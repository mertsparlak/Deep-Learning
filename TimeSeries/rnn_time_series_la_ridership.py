# -*- coding: utf-8 -*-
"""RNN_Time_series_LA_Ridership.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e1v1pW6bcpgANnrjHhW6RN6nTRj1MzPR
"""

import tensorflow as tf

tf.keras.utils.get_file("ridership.tgz",
                        "https://github.com/TirendazAcademy/Deep-Learning-with-TensorFlow/raw/main/Data/ridership.tgz",
                        cache_dir=".",
                        extract=True)

import pandas as pd
from pathlib import Path

path=Path("/content/datasets/ridership_extracted/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv")
df=pd.read_csv(path,parse_dates=["service_date"])
df.columns=["date","day_type","bus","rail","total"]
df=df.sort_values("date").set_index("date")
df=df.drop("total",axis=1)
df=df.drop_duplicates()

df.head()

import matplotlib.pyplot as plt
df["2019-03":"2019-05"].plot(grid=True,marker=".",figsize=(8,3.5))
plt.show()

"""# **Naive Tahmin**"""

diff_7=df[["bus","rail"]].diff(7)["2019-03":"2019-05"]
fig,axs=plt.subplots(2,1,sharex=True,figsize=(8,5))
df.plot(ax=axs[0],grid=True,marker=".")
df.shift(7).plot(ax=axs[0],grid=True,legend=False,linestyle=":") #tahmin için
diff_7.plot(ax=axs[1],grid=True,legend=False) #önceki haftaya göre karşılaştırması
plt.show()

diff_7.abs().mean() #

targets=df[["bus","rail"]]["2019-03":"2019-05"]

(diff_7/targets).abs().mean() #hata oranı %8

period=slice("2001","2019")

df_monthly = df.resample("ME")[['bus', 'rail']].mean() # Select only numerical columns 'bus' and 'rail'
rolling_average_12_months=df_monthly[period].rolling(window=12).mean()

fig,ax=plt.subplots(figsize=(8,4))
df_monthly[period].plot(ax=ax,marker=".")
rolling_average_12_months.plot(ax=ax,grid=True,legend=False)
plt.show()

df_monthly.diff(12)[period].plot(grid=True,marker=".",figsize=(8,3))

rail_train = df["rail"]["2016-01":"2018-12"]/1e6
rail_valid = df["rail"]["2019-01":"2019-05"]/1e6
rail_test = df["rail"]["2019-05":]/1e6

seq_length = 56
train_ds = tf.keras.utils.timeseries_dataset_from_array(
    rail_train.to_numpy(),
    targets=rail_train[seq_length:],
    sequence_length=seq_length,
    batch_size=32,
    shuffle=True,
    seed = 42
)

valid_ds = tf.keras.utils.timeseries_dataset_from_array(
    rail_valid.to_numpy(),
    targets=rail_valid[seq_length:],
    sequence_length=seq_length,
    batch_size=32
)

tf.random.set_seed(42)
model = tf.keras.Sequential([
    tf.keras.layers.Dense(1, input_shape=[seq_length])
])

early_stopping_cb = tf.keras.callbacks.EarlyStopping(
    monitor="val_mae", patience = 30, restore_best_weights=True
)

opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)

model.compile(loss=tf.keras.losses.Huber(),
              optimizer=opt,
              metrics=["mae"])

history = model.fit(train_ds,
                    validation_data=valid_ds,
                    epochs=100,
                    callbacks=[early_stopping_cb])

valid_loss, valid_mae = model.evaluate(valid_ds)
valid_mae*1e6

tf.random.set_seed(42)
univar_model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),
    tf.keras.layers.Dense(1)
])

"""# **Simply RNN**"""

def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs = 100):
  early_stopping_cb = tf.keras.callbacks.EarlyStopping(
    monitor="val_mae", patience = 30, restore_best_weights=True)
  opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)
  model.compile(loss=tf.keras.losses.Huber(),
              optimizer=opt,
              metrics=["mae"])
  history = model.fit(train_set,
                    validation_data=valid_set,
                    epochs=epochs,
                    callbacks=[early_stopping_cb])
  valid_loss, valid_mae = model.evaluate(valid_set)
  return valid_mae * 1e6

fit_and_evaluate(univar_model, train_ds, valid_ds, learning_rate = 0.05)

"""# **Deep RNN**"""

tf.random.set_seed(42)
deep_model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(32, return_sequences=True,
                              input_shape=[None, 1]),
    tf.keras.layers.SimpleRNN(32, return_sequences=True),
    tf.keras.layers.SimpleRNN(32, return_sequences=True),
    tf.keras.layers.Dense(1)
])

fit_and_evaluate(deep_model, train_ds, valid_ds, learning_rate=0.01)

import numpy as np

X = rail_valid.to_numpy()[np.newaxis, :seq_length, np.newaxis]
X.shape

for step_ahead in range(14):
  y_pred_one = univar_model.predict(X)
  X = np.concatenate([X, y_pred_one.reshape(1,1,1)], axis=1)

Y_pred = pd.Series(X[0,-14:,0],
                   index=pd.date_range("2019-02-26","2019-03-11"))

fig, ax = plt.subplots(figsize=(8,3.5))
(rail_valid*1e6)["2019-02-01":"2019-03-11"].plot(label=True, marker=".",
                                                 ax=ax)
(Y_pred*1e6).plot(label="Predictions", grid=True, marker="x", color="r",
                  ax = ax)
ax.set_ylim([200_000, 800_000])
plt.legend()
plt.show()