# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yyKd3jGYprWVz9J5zp8EQPD1XjHcRapV
"""

import tensorflow as tf

dataset=tf.data.Dataset.range(10)
dataset=dataset.window(5,shift=1,drop_remainder=True) #pencere büyüklüğü 5, her eleman 1 kayıyor pencere 5 den küçükse dropluyor
dataset=dataset.flat_map(lambda window:window.batch(5))
for window in dataset:
  print(window.numpy())

dataset=tf.data.Dataset.range(10)
dataset=dataset.window(5,shift=1,drop_remainder=True) #pencere büyüklüğü 5, her eleman 1 kayıyor pencere 5 den küçükse dropluyor
dataset=dataset.flat_map(lambda window:window.batch(5))
dataset=dataset.map(lambda window:(window[:-1],window[-1:]))
for x,y in dataset:
  print(x.numpy(),y.numpy())

dataset=dataset.shuffle(buffer_size=10)
dataset=dataset.batch(2).prefetch(1) #optimize etmek için prefetch
print(dataset)
for x,y in dataset:
  print("x=",x.numpy())
  print("y=",y.numpy())

"""# **Zaman serisi için veri seti oluşturma**"""

import numpy as np

def trend(time, slope=0):
    return slope * time #verinin genel eğimini belirleyen tredn

def seasonal_pattern(season_time):
    return np.where(season_time < 0.4,
            np.cos(season_time * 2 * np.pi),
            1 / np.exp(3 * season_time)) #verideki mevsimsellik (belirli aralıklarda inişler çıkışlar)

def seasonality(time, period, amplitude=1, phase=0):
    season_time = ((time + phase) % period) / period
    return amplitude * seasonal_pattern(season_time)


def noise(time, noise_level=1, seed=None):
    rnd = np.random.RandomState(seed)
    return rnd.randn(len(time)) * noise_level #veri setinde öngörülemeyen gürültü olabilir onu ekliyoruz

time = np.arange(4*365+1,dtype="float32")

baseline = 10
series = trend(time, .05)
amplitude = 15
slope=0.09
noise_level = 6

series = baseline+trend(time,slope)+seasonality(time,period=365,
                                                amplitude=amplitude)
series +=noise(time, noise_level, seed = 42)

import matplotlib.pyplot as plt

def plot_series(time, series, format="-", start=0, end=None):
    plt.plot(time[start:end], series[start:end], format)
    plt.xlabel("Time")
    plt.ylabel("Value")
    plt.grid(True)

plt.figure(figsize=(10, 6))
plot_series(time,series)

"""# **Veri** **Ön** **İşleme**"""

def windowed_dataset(series,window_size,batch_size,shuffle_buffer):
  dataset=tf.data.Dataset.from_tensor_slices(series)
  dataset=dataset.window(window_size+1,shift=1,drop_remainder=True)
  dataset=dataset.flat_map(lambda window:window.batch(window_size+1))
  dataset=dataset.shuffle(shuffle_buffer).map(lambda window:(window[:-1],window[-1]))
  dataset=dataset.batch(batch_size).prefetch(1)
  return dataset

split_time=1000
time_train=time[:split_time]
x_train=series[:split_time]
time_valid=time[split_time:]
x_valid=series[split_time:]

def plot_series(time,series,format="-",start=0,end=None):
  plt.plot(time[start:end],series[start:end],format)
  plt.xlabel("Time")
  plt.ylabel("Value")
  plt.grid(True)

plt.figure(figsize=(10,6))
plot_series(time_valid,x_valid)

window_size= 20
batch_size= 32
shuffle_buffer_size=1000

dataset=windowed_dataset(x_train,window_size,batch_size,shuffle_buffer_size)

for feature,label in dataset.take(1):
  print(feature[:1])
  print(label[:1])

"""# **Sinir Ağı Modeli Oluşturma**"""

model=tf.keras.models.Sequential([
    tf.keras.layers.Dense(10,input_shape=[window_size],activation="relu"),
    tf.keras.layers.Dense(10,activation="relu"),
    tf.keras.layers.Dense(1)
])

model.compile(loss="mse",optimizer=tf.keras.optimizers.Adam())

model.fit(dataset,epochs=100)

series[1000:1020]

series[1020]

model.predict(series[1000:1020][np.newaxis]) #1020 yi tahmin ettirdik

forecast= []
for time in range(len(series)-window_size):
  forecast.append(model.predict(series[time:time+window_size][np.newaxis]))

len(forecast)

forecast=forecast[split_time-window_size:]
results=np.array(forecast)[:,0,0]

plt.figure(figsize=(10,6))
plot_series(time_valid,x_valid)
plot_series(time_valid,results)

tf.keras.metrics.mean_absolute_error(x_valid,results).numpy()